#!/usr/bin/python
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.

# This is a DOCUMENTATION stub specific to this module, it extends
# a documentation fragment located in ansible.utils.module_docs_fragments
import socket, sys, time, ConfigParser, csv, pprint, urllib2
from subprocess import Popen, PIPE, STDOUT
from math import log as ln
from cm_api.api_client import ApiResource
from cm_api.api_client import ApiException
from cm_api.endpoints.services import ApiService
from cm_api.endpoints.services import ApiServiceSetupInfo

DOCUMENTATION = '''
---
module: cloudera_init
short_description: create / delete a Cloudera cluster
description:
     - creates / deletes a Cloudera cluster using Cloudera Manager.
version_added: "2.1"
options:
  name:
    description:
      - Name to be given to the cluster
    default: null
  fullVersion:
    description:
      - Full version of the cluster
    default: 5.6.0
  admin_password:
    description:
      - Password of the admin account for the cluster
    default: admin
  cm_host:
    description:
      - Hostname of the node running Cloudera Manager
    default: localhost
  hosts:
    description:
      - Comma separated hostnames of the nodes forming the cluster
    default: null
  state:
    description:
      - Indicate desired state of the resource
    choices:
      - present
      - absent
    default: present
author: Alexandru Anghel, David Grier
'''

EXAMPLES = '''
- name: Build a Cloudera cluster
  gather_facts: False
  hosts: local
  connection: local
  tasks:
    - name: Cloudera cluster create request
      local_action:
        module: cloudera_init
        name: my-test-cluster
        fullVersion: 5.6.0
        admin_password: admin
        cm_host: localhost
        hosts: localhost
        state: present
      register: my_cdh

    - debug: var=my_cdh
'''


def find_cluster(module, api, name):
    try:
        cluster = api.get_cluster(name)
        if not cluster:
            return None

    except ApiException as e:
        if e.code == 404:
            return None
        module.fail_json(msg='Failed to get cluster.\nError is %s' % e)

    return cluster


def init_cluster(module, api, name, fullVersion, hosts, cm_host):

    changed = False
    cluster = find_cluster(module, api, name)

    if not cluster:
        try:
            cluster = api.create_cluster(name, fullVersion=fullVersion)
            all_hosts = set(hosts.split(','))
            all_hosts.add(cm_host)
            cluster.add_hosts(all_hosts)
            changed = True
            time.sleep(10)
        except ApiException as e:
            module.fail_json(msg='Failed to build cluster.\nError is %s' % e)

    result = dict(changed=changed, cluster=cluster.name)
    module.exit_json(**result)


def delete_cluster(module, api, name):

    changed = False
    cluster = find_cluster(module, api, name)
    if cluster:
        try:
            api.delete_cluster(name)
            changed = True
            time.sleep(5)
        except ApiException as e:
            module.fail_json(msg='Failed to delete cluster.\nError is %s' % e)
    else:
        module.fail_json(msg='Cluster does not exist.')

    result = dict(changed=changed, cluster=cluster.name)
    module.exit_json(**result)

def build_service_list(module, api, name):
    
    changed = False
    service_types_and_names = {
			   "ZOOKEEPER" : "ZOOKEEPER-1",
			   "HDFS" : "HDFS-1",
			   "MAPREDUCE" : "MAPREDUCE-1",
			   "HBASE" : "HBASE-1",
			   "OOZIE" : "OOZIE-1",
			   "HIVE" : "HIVE-1",
			   "HUE" : "HUE-1",
			   "IMPALA" : "IMPALA-1",
			   "SOLR" : "SOLR-1",
			   "SQOOP" : "SQOOP-1" }

def auto_prov_cluster(module, api, name):

    changed = False

    parcels_list = []
    cluster = find_cluster(module, api, name)

    if cluster:

        try:
            for p in cluster.get_all_parcels():
    
                if p.version.startswith(cdh_version_number) and p.product == "CDH":
                    parcels_list.append(p)

        except ApiException as e:
            module.fail_json(msg='cant find cluster.\nError is %s' % e)

    try:
        len(parcels_list) > 0
    except ApiException as e:
        module.fail_json(msg='No parcel found!.\nError is %s' % e)
    
    cdh_parcel = parcels_list[0]

    for p in parcels_list:
        if p.version > cdh_parcel.version:
            cdh_parcel = p

    #download parcel
    cmd = cdh_parcel.start_download()
    if cmd.success != True:
        print "Parcel download failed!"
        exit(0)

    # make sure the download finishes
    while cdh_parcel.stage != 'DOWNLOADED':
        sleep(5)
        cdh_parcel = get_parcel(api, cdh_parcel.product, cdh_parcel.version, cluster_name)

    # distribute the parcel
    cmd = cdh_parcel.start_distribution()

    try:
        cmd.success
    except ApiException as e:
        module.fail_json(msg='Parcel distribution failed!.\nError is %s' % e)
    
    # make sure the activation finishes
    cmd = cdh_parcel.activate()

    try:
        cmd.success 
    except ApiException as e:
        module.fail_json(msg-'Parcel activation failed!.\nError is %s' % e)

    # make sure the activation finishes
    while cdh_parcel.stage != "ACTIVATED":
        cdh_parcel = get_parcel(api, cdh_parcel.product, cdh_parcel.version, cluster_name)

    cmd = cm.inspect_hosts()
    while cmd.success == None:
        cmd = cmd.fetch()

    try:
        cmd.success
    except ApiException as e:
        module.fail_json(msg='Host inpsection failed!.\nError is %s' % e)

    for s in service_types_and_names.keys():
        service = cluster.create_service(service_types_and_names[s], s)

    # we will auto-assign roles; you can manually assign roles using the
    # /clusters/{clusterName}/services/{serviceName}/role endpoint or by using
    # ApiService.createRole()
    cluster.auto_assign_roles()
    cluster.auto_configure()

    # this will set up the Hive and the reports manager databases because we
    # can't auto-configure those two things
    hive = cluster.get_service(service_types_and_names["HIVE"])
    hive_config = { "hive_metastore_database_host" : hive_metastore_host, \
                    "hive_metastore_database_name" : hive_metastore_name, \
                    "hive_metastore_database_password" : hive_metastore_password, \
	    	    "hive_metastore_database_port" : hive_metastore_database_port, \
		    "hive_metastore_database_type" : hive_metastore_database_type }
    hive.update_config(hive_config)


    rm_rcg.update_config(rm_rcg_config)

    # restart the management service with new configs
    cm_service.restart().wait()

    # this will set the Reports Manager database password
    # first we find the correct role
    rm_role = None
    for r in cm.get_service().get_all_roles():
        if r.type == "REPORTSMANAGER":
            rm_role = r

    try:
        rm_role != None
    except ApiException as e:
        module.fail_json(msg='No REPORTSMANAGER role found!.\nError is %s' % e)

    # then we get the corresponding role config group -- even though there is
    # only once instance of each CM management service, we do this just in case
    # it is not placed in the base group
    rm_role_group = rm_role.roleConfigGroupRef
    rm_rcg = get_role_config_group(api, rm_role.type, \
                rm_role_group.roleConfigGroupName, None)

    # update the appropriate fields in the config
    rm_rcg_config = { "headlamp_database_host" : reports_manager_host, \
                      "headlamp_database_name" : reports_manager_name, \
                      "headlamp_database_user" : reports_manager_username, \
                      "headlamp_database_password" : reports_manager_password, \
 		      "headlamp_database_type" : reports_manager_database_type }

    rm_rcg.update_config(rm_rcg_config)

    # restart the management service with new configs
    cm_service.restart().wait()

    # execute the first run command
    print "Excuting first run command. This might take a while."
    cmd = cluster.first_run()

    while cmd.success == None:
        cmd = cmd.fetch()

    if cmd.success != True:
        print "The first run command failed: " + cmd.resultMessage()
        exit(0)

    result = dict(changed=changed, cluster=cluster.name)
    module.exit_json(**result)

def main():
    argument_spec = dict(
        name=dict(type='str'),
        fullVersion=dict(type='str', default='5.6.0'),
        admin_password=dict(type='str', default='admin'),
        state=dict(default='present', choices=['present', 'absent']),
        cm_host=dict(type='str', default='localhost'),
        hosts=dict(type='str', default=''),
        trial=dict(type='bool', default=True),
        auto_prov=dict(type='bool', default=True),
        wait=dict(type='bool', default=False),
        wait_timeout=dict(default=30),
        hive_metastore_host=dict(type='str', default='localhost'),
        hive_metastore_name=dict(type='str', default='metastore'),
        hive_metastore_password=dict(type='str', default='temp'),
        hive_metastore_database_port=dict(type='str', default='3306'),
        hive_metastore_database_type=dict(type='str', default='mysql'),
        reports_manager_host=dict(type='str', default='localhost'),
        reports_manager_name=dict(type='str', default='rman'),
        reports_manager_username=dict(type='str', default='rman'),
        reports_manager_password=dict(type='str', default='temp'),
        reports_manager_database_type=dict(type='str', default='mysql')   
    )

    module = AnsibleModule(
        argument_spec=argument_spec
    )

    name = module.params.get('name')
    fullVersion = module.params.get('fullVersion')
    admin_password = module.params.get('admin_password')
    state = module.params.get('state')
    cm_host = module.params.get('cm_host')
    hosts = module.params.get('hosts')
    trial = module.params.get('trial')
    auto_prov = module.params.get('auto_prov')
    wait = module.params.get('wait')
    wait_timeout = int(module.params.get('wait_timeout'))
    hive_metastore_host = module.params.get('hive_metastore_host')
    hive_metastore_name = module.params.get('hive_metastore_name')
    hive_metastore_password = module.params.get('hive_metastore_password')
    hive_metastore_database_port = module.params.get('hive_metastore_database_port')
    hive_metastore_database_type = module.params.get('hive_metastore_database_type')
    reports_manager_host = module.params.get('reports_manager_host')
    reports_manager_name = module.params.get('reports_manager_name')
    reports_manager_username = module.params.get('reports_manager_username')
    reports_manager_password = module.params.get('reports_manager_password')
    reports_manager_database_type = module.params.get('reports_manager_database_type')

    if not name:
        module.fail_json(msg='The cluster name is required for this module')

    cfg = ConfigParser.SafeConfigParser()

    try:
        API = ApiResource(cm_host, version=fullVersion[0], username="admin", password=admin_password)
        MANAGER = API.get_cloudera_manager()
        if trial:
            MANAGER.begin_trial()
    except ApiException as e:
        module.fail_json(msg='Failed to connect to Cloudera Manager.\nError is %s' % e)

    if state == "absent":
        delete_cluster(module, API, name)
    else:
        init_cluster(module, API, name, fullVersion, hosts, cm_host)
            
        if auto_prov == True:
            auto_provision_cluster(module, API, name, fullVersion, hosts, cm_host)
         

# import module snippets
from ansible.module_utils.basic import *

### invoke the module
main()
